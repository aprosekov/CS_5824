{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_mode = \"rgb\"\n",
    "number_colour_layers = 3\n",
    "image_size = (640, 640)\n",
    "image_shape = image_size + (number_colour_layers,)\n",
    "batch_size = 4\n",
    "img_width = 640\n",
    "img_height = 640\n",
    "training_data_path = \"Train/*\"\n",
    "test_data_path = \"Test\"\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23730 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "img_folder = \"GSVImages/\"\n",
    "\n",
    "imgs = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    img_folder, \n",
    "    batch_size=32, \n",
    "    image_size=(640,640),\n",
    "    labels = None,\n",
    ")\n",
    "paths = imgs.file_paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Chuck bellow removes bad images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from struct import unpack\n",
    "# from tqdm import tqdm\n",
    "# import os\n",
    "# import os.path as osp\n",
    "\n",
    "# marker_mapping = {\n",
    "#     0xffd8: \"Start of Image\",\n",
    "#     0xffe0: \"Application Default Header\",\n",
    "#     0xffdb: \"Quantization Table\",\n",
    "#     0xffc0: \"Start of Frame\",\n",
    "#     0xffc4: \"Define Huffman Table\",\n",
    "#     0xffda: \"Start of Scan\",\n",
    "#     0xffd9: \"End of Image\"\n",
    "# }\n",
    "\n",
    "\n",
    "# class JPEG:\n",
    "#     def __init__(self, image_file):\n",
    "#         with open(image_file, 'rb') as f:\n",
    "#             self.img_data = f.read()\n",
    "    \n",
    "#     def decode(self):\n",
    "#         data = self.img_data\n",
    "#         while(True):\n",
    "#             marker, = unpack(\">H\", data[0:2])\n",
    "#             # print(marker_mapping.get(marker))\n",
    "#             if marker == 0xffd8:\n",
    "#                 data = data[2:]\n",
    "#             elif marker == 0xffd9:\n",
    "#                 return\n",
    "#             elif marker == 0xffda:\n",
    "#                 data = data[-2:]\n",
    "#             else:\n",
    "#                 lenchunk, = unpack(\">H\", data[2:4])\n",
    "#                 data = data[2+lenchunk:]            \n",
    "#             if len(data)==0:\n",
    "#                 break        \n",
    "\n",
    "\n",
    "# bads = []\n",
    "# root_img = \"C:\\ML\"\n",
    "# for i in tqdm(paths):\n",
    "#   image = osp.join(root_img,i)\n",
    "#   image = JPEG(image) \n",
    "#   try:\n",
    "#     image.decode()   \n",
    "#   except:\n",
    "#     bads.append(i)\n",
    "\n",
    "\n",
    "# for name in bads:\n",
    "#   os.remove(osp.join(root_img,name))\n",
    "# print(bads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Panoid_Heat_lable.csv')\n",
    "l = df['panoid'].apply(len)\n",
    "df['len'] = l\n",
    "df.drop(df.loc[df['len']!=22].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = pd.DataFrame()\n",
    "pf['path'] = paths\n",
    "pf['temp'] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(23730):\n",
    "    s = pf.iloc[i]['path'][11:33]\n",
    "    temp = df[df['panoid'] == s]['ht_ndx_c']\n",
    "    pf.at[i,'temp'] = temp.values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(123)\n",
    "train, test = train_test_split(pf, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = train['temp'].to_numpy().astype('float32')\n",
    "dataset = tf.data.Dataset.from_tensor_slices((train['path'],label ))\n",
    "label_test = test['temp'].to_numpy().astype('float32')\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((test['path'],label_test ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(filename, label):\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    image = tf.cast(image_decoded, tf.float32)\n",
    "    return image, label\n",
    "\n",
    "dataset = dataset.map(_parse_function)\n",
    "dataset = dataset.batch(2)\n",
    "dataset_test = dataset_test.map(_parse_function)\n",
    "dataset_test = dataset_test.batch(4)\n",
    "\n",
    "# step 4: create iterator and final input tensor\n",
    "iterator = iter(dataset)\n",
    "iterator_test = iter(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential([\n",
    "#   layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "#   layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "#   layers.MaxPooling2D(),\n",
    "#   layers.Dropout(.05),\n",
    "#   layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "#   layers.MaxPooling2D(),\n",
    "#   layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "#   layers.MaxPooling2D(),\n",
    "#   layers.Flatten(),\n",
    "#   layers.Dense(1, activation='linear'),\n",
    "# ])\n",
    "# opt = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "# model.compile(loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model and use that\n",
    "model = tf.keras.models.load_model(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling (Rescaling)        (None, 640, 640, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 640, 640, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 320, 320, 16)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 320, 320, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 320, 320, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 160, 160, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 160, 160, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 80, 80, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 409600)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 409601    \n",
      "=================================================================\n",
      "Total params: 433,185\n",
      "Trainable params: 433,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs=10\n",
    "# history = model.fit(\n",
    "#   dataset,\n",
    "#   validation_data=dataset_test,\n",
    "#   epochs=epochs\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    }
   ],
   "source": [
    "#model.save('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        true       pred      diff\n",
      "0  26.211111  27.502531 -1.291420\n",
      "1  28.549084  27.046732  1.502352\n",
      "2  28.473185  27.224792  1.248392\n",
      "3  28.751080  28.506205  0.244875\n"
     ]
    }
   ],
   "source": [
    "image, label = iterator_test.get_next()\n",
    "\n",
    "pred = model.predict(image)\n",
    "output = pd.DataFrame()\n",
    "output['true'] = label\n",
    "output['pred'] = pred\n",
    "output['diff'] = output['true'] - output['pred']\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "91641b3beeb78b779d9e05bfa46b972b93d7bd45282eeec0d03b78c3155fd926"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
